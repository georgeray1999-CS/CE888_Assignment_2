{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project 2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "UmiZ9w45CKUH",
        "D596ZNi0E4EZ",
        "L2KRFS7rJRv_"
      ],
      "mount_file_id": "14nEYz_ngzYVGdNkExY6fH-oLz3I2nko5",
      "authorship_tag": "ABX9TyNk+1OI5FBNm7yoNtUAEDXH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/georgeray1999-CS/CE888_Assignment_2/blob/main/model_code/Project_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9u0shB_C5sR"
      },
      "source": [
        "# Project 2 - Tweet Semantics Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBU6ff_QHvKf"
      },
      "source": [
        "This notebook takes the form of first loading in the relevant task data. The data is then prepared for the Naive Bayes, SVM and neural network models. After this, the models are trained and optimized using a grid search algorithm. Different classifers are commented out depending on their task as different tasks require different hyperparameters. Due to the increased number of variables associated with deep neural network structure, a cell exists defining the model for each task. A comment will be provided to indicate which model refers to which task. Some models take some time to train, in this case, a warning will be issued as a comment prior to running the training process. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmiZ9w45CKUH"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxnuknu3DA86"
      },
      "source": [
        "Please enure that the relevant training, validation and test csv files for the task have been uploaded to the runtime to allow the following function to load the correct infrmation to be analysed. Please also note that the following code is written for Google Colab, please alter the file path accordingly if using a different IPython environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka6Zv-K9ZNq-"
      },
      "source": [
        "# urls for importing data from GitHub\n",
        "emotion_base_url = 'https://raw.githubusercontent.com/georgeray1999-CS/CE888_Assignment_2/main/processed_data/emotion/'\n",
        "offensive_base_url = 'https://raw.githubusercontent.com/georgeray1999-CS/CE888_Assignment_2/main/processed_data/offensive/'\n",
        "sentiment_base_url = 'https://raw.githubusercontent.com/georgeray1999-CS/CE888_Assignment_2/main/processed_data/sentiment/'\n",
        "\n",
        "def create_urls(base_url):\n",
        "  \"\"\"Add correct path endings to urls\"\"\"\n",
        "  train_url = base_url + 'train_df.csv'\n",
        "  val_url = base_url + 'validation_df.csv'\n",
        "  test_url = base_url + 'test_df.csv'\n",
        "\n",
        "  return [train_url, val_url, test_url]\n",
        "\n",
        "# change the imput depending on the task to be completed\n",
        "urls = create_urls(sentiment_base_url)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nwetQwUauVC"
      },
      "source": [
        "# load data into pandas dataframes\n",
        "import pandas as pd\n",
        "\n",
        "def load_data(url_list):\n",
        "  \"\"\"This function loads in the data frames created in the pythin scripts to preprocess the data\"\"\"\n",
        "\n",
        "  training_data = pd.read_csv(url_list[0])\n",
        "  val_data = pd.read_csv(url_list[1])\n",
        "  test_data = pd.read_csv(url_list[2])\n",
        "\n",
        "  return training_data, val_data, test_data\n",
        "\n",
        "training_df, val_df, test_df = load_data(urls)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZBSnf3GEfo1"
      },
      "source": [
        "# run this cell to check the data has been uploaded correctly\n",
        "training_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qj4ZjUcCEp-6"
      },
      "source": [
        "# convert all data to list format to process\n",
        "train_tweets = training_df['Text'].tolist()\n",
        "val_tweets = val_df['Text'].tolist()\n",
        "test_tweets = test_df['Text'].tolist()\n",
        "\n",
        "train_labels = training_df['Target'].tolist()\n",
        "val_labels = val_df['Target'].tolist()\n",
        "test_labels = test_df['Target'].tolist()"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D596ZNi0E4EZ"
      },
      "source": [
        "## Text Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oVoli7JE747"
      },
      "source": [
        "Classical algorithm preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5xhzqzBE48s"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "# create count vector\n",
        "count_vector = CountVectorizer()\n",
        "X_train_counts = count_vector.fit_transform(train_tweets)\n",
        "X_val_counts = count_vector.transform(val_tweets)\n",
        "X_test_counts = count_vector.transform(test_tweets)\n",
        "\n",
        "# transform to tfidf matrix\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "X_val_tfidf = tfidf_transformer.transform(X_val_counts)\n",
        "X_test_tfidf = tfidf_transformer.transform(X_test_counts)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4r3KeAXE_Zv"
      },
      "source": [
        "Neural network data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pji3JGF4FjQZ"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# tokenize tweets\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(train_tweets)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(train_tweets)\n",
        "X_val = tokenizer.texts_to_sequences(val_tweets)\n",
        "X_test = tokenizer.texts_to_sequences(test_tweets)\n",
        "\n",
        "# set vocab size and add 1 to account for 0 padding index\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "# print to make make sure process executed as expected\n",
        "print(train_tweets[0])\n",
        "print(X_train[0])\n",
        "\n",
        "# set maximum input length\n",
        "max_length = 30\n",
        "\n",
        "# pad out sequences\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=max_length)\n",
        "X_val = pad_sequences(X_val, padding='post', maxlen=max_length)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=max_length)\n",
        "\n",
        "# make sure sequences padded correctly\n",
        "print(X_train[0, :])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Hg_LqDIFqy-"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "# create numpy array of labels\n",
        "y_train = np.array(train_labels)\n",
        "y_val = np.array(val_labels)\n",
        "y_test = np.array(test_labels)\n",
        "\n",
        "# one hot encode the labels\n",
        "oh_encoder = OneHotEncoder()\n",
        "\n",
        "y_train_coded = oh_encoder.fit_transform((y_train.reshape(len(y_train), 1))).toarray()\n",
        "y_val_coded = oh_encoder.fit_transform((y_val.reshape(len(y_val), 1))).toarray()\n",
        "y_test_coded = oh_encoder.fit_transform((y_test.reshape(len(y_test), 1))).toarray()"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5SrpiAkFvyJ"
      },
      "source": [
        "##Build Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_fU-QBsFzJ0"
      },
      "source": [
        "Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIyDw0F7Fz2x"
      },
      "source": [
        "!pip install hypopt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNh4bmRxGCPJ"
      },
      "source": [
        "# this cell is purely to provie proof of the optimization process, cell below has correct set of hyperparameters\n",
        "# perform a gridsearch for the best parameters for the NB model\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from hypopt import GridSearch\n",
        "tuned_parameters = [{'alpha': [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]}]\n",
        "\n",
        "clf = GridSearch(model=MultinomialNB(), param_grid=tuned_parameters)\n",
        "\n",
        "clf.fit(X_train_tfidf, train_labels, X_val_tfidf, val_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "506XHTg9GLIe"
      },
      "source": [
        "# produce final predictions\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
        "import seaborn as sns\n",
        "\n",
        "# train optimal model - uncomment to train correct model for task\n",
        "nb_clf = MultinomialNB(alpha=0.01).fit(X_train_tfidf, train_labels)  # emotion model\n",
        "# nb_clf = MultinomialNB(alpha=0.08).fit(X_train_tfidf, train_labels)  # offensive model\n",
        "# nb_clf = MultinomialNB(alpha=0.08).fit(X_train_tfidf, train_labels)  # sentiment model\n",
        "\n",
        "# predict values\n",
        "predicted = nb_clf.predict(X_test_tfidf)\n",
        "\n",
        "# check accuracy\n",
        "accuracy = accuracy_score(test_labels, predicted)\n",
        "conf_matrix = confusion_matrix(test_labels, predicted)\n",
        "print(\"Accuracy: \", accuracy)\n",
        "\n",
        "# display macro-F1 score\n",
        "f1 = f1_score(test_labels, predicted, average='macro')\n",
        "print(\"f1 score: \", f1)\n",
        "\n",
        "# display confusion matrix\n",
        "sns.heatmap(conf_matrix, annot=True, fmt = \".0f\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLovpEhhGiBU"
      },
      "source": [
        "SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-x2jhXWGdwN"
      },
      "source": [
        "# this cell is purely to provie proof of the optimization process, cell below has correct set of hyperparameters\n",
        "# please note that training for offensive and sentiment tasks takes time\n",
        "# perform a gridsearch for the best parameters for the SVM model\n",
        "from sklearn.svm import SVC\n",
        "from hypopt import GridSearch\n",
        "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]},\n",
        "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
        "\n",
        "clf = GridSearch(model=SVC(), param_grid=tuned_parameters)\n",
        "\n",
        "clf.fit(X_train_tfidf, train_labels, X_val_tfidf, val_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzblvAU5GwXC"
      },
      "source": [
        "# produce final predictions\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
        "import seaborn as sns\n",
        "\n",
        "# train optimal model - uncomment to train correct model\n",
        "svm_clf = SVC(C=1, kernel='linear', gamma=0.0001).fit(X_train_tfidf, train_labels)  # emotion model\n",
        "# svm_clf = SVC(C=1, kernel='linear', gamma=0.0001).fit(X_train_tfidf, train_labels)  # offensive model\n",
        "# svm_clf = SVC().fit(X_train_tfidf, train_labels)  # sentiment model\n",
        "\n",
        "# predict values\n",
        "predicted = svm_clf.predict(X_test_tfidf)\n",
        "\n",
        "# check accuracy\n",
        "accuracy = accuracy_score(test_labels, predicted)\n",
        "conf_matrix = confusion_matrix(test_labels, predicted)\n",
        "print(\"Accuracy: \", accuracy)\n",
        "\n",
        "# display macro-F1 score\n",
        "f1 = f1_score(test_labels, predicted, average='macro')\n",
        "print(\"f1 score: \", f1)\n",
        "\n",
        "# display confusion matrix\n",
        "sns.heatmap(conf_matrix, annot=True, fmt = \".0f\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNjySck6HM3W"
      },
      "source": [
        "CNN - LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Nrc6AyyHOXr"
      },
      "source": [
        "# optimized for emotion task\n",
        "from keras.models import Sequential\n",
        "from keras.layers import *\n",
        "\n",
        "embedding_dim = 100\n",
        "\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, input_length=max_length))\n",
        "model.add(Conv1D(128, 5, activation='relu'))\n",
        "model.add(MaxPooling1D())\n",
        "model.add(Conv1D(64, 3, activation='relu'))\n",
        "model.add(MaxPooling1D())\n",
        "model.add(Bidirectional(LSTM(64)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "# compile model and print summary\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# fit model and save history\n",
        "history = model.fit(X_train, y_train_coded,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_data=(X_val, y_val_coded),\n",
        "                    batch_size=10)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxPYYD2NKeq2"
      },
      "source": [
        "# optimized for offensive task\n",
        "from keras.models import Sequential\n",
        "from keras.layers import *\n",
        "\n",
        "embedding_dim = 100\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(vocab_size, embedding_dim, input_length=max_length))\n",
        "model.add(Conv1D(128, 3, activation='relu'))\n",
        "model.add(MaxPooling1D())\n",
        "model.add(Bidirectional(LSTM(32)))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# compile model an print summary\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# fit model and save history\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=5,\n",
        "                    verbose=1,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    batch_size=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_M1b6nQLHZx"
      },
      "source": [
        "# optimized for sentiment task\n",
        "from keras.models import Sequential\n",
        "from keras.layers import *\n",
        "\n",
        "embedding_dim = 100\n",
        "\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, input_length=max_length))\n",
        "model.add(Conv1D(128, 5, activation='relu'))\n",
        "model.add(MaxPooling1D())\n",
        "model.add(Bidirectional(LSTM(32)))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# compile model an print summary\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# fit model and save history\n",
        "history = model.fit(X_train, y_train_coded,\n",
        "                    epochs=2,\n",
        "                    verbose=1,\n",
        "                    validation_data=(X_val, y_val_coded),\n",
        "                    batch_size=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3Wjzz39LHw3"
      },
      "source": [
        "Validation and testing results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbQgNWJ4Hdjq"
      },
      "source": [
        "# please use y_train, y_val and y_test for offensive task an y_train_coded, y_val_coded and y_test_coded for emotion and sentiment tasks\n",
        "# print training accuracy\n",
        "loss, accuracy = model.evaluate(X_train, y_train_coded, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "#print validation accuracy\n",
        "loss, accuracy = model.evaluate(X_val, y_val_coded, verbose=False)\n",
        "print(\"Validation Accuracy:  {:.4f}\".format(accuracy))\n",
        "\n",
        "# find argmax of highest value and return as list\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# create list of predicted classes - please uncomment as appropriate\n",
        "# use for emotion and sentiment task\n",
        "predicted = []\n",
        "for i in predictions:\n",
        "  predicted.append(np.argmax(i))\n",
        "\n",
        "# use for offensive task\n",
        "# predicted = predictions.round()\n",
        "\n",
        "# print f1 score\n",
        "from sklearn.metrics import f1_score\n",
        "f1 = f1_score(test_labels, predicted, average='macro')\n",
        "print(\"F1 score: \", f1)\n",
        "\n",
        "# plot results\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# plot accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# plot loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# display confusion matrix\n",
        "conf_matrix = confusion_matrix(test_labels, predicted)\n",
        "sns.heatmap(conf_matrix, annot=True, fmt = \".0f\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2KRFS7rJRv_"
      },
      "source": [
        "## BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IurGlhXNV2Gr"
      },
      "source": [
        "!pip install ktrain"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zObUtayOcayA"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import ktrain\n",
        "from ktrain import text"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjKRrBhmd4UC"
      },
      "source": [
        "training_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQQLL3mkd95Z"
      },
      "source": [
        "# create train and validation set\n",
        "(X_train, y_train), (X_val, y_val), preprocess = text.texts_from_df(train_df=training_df, \n",
        "                   text_column='Text',\n",
        "                   label_columns='Target',\n",
        "                   val_df=val_df,\n",
        "                   maxlen=400,\n",
        "                   preprocess_mode='bert')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6QbDpmlf1U7"
      },
      "source": [
        "# check correct data loaded\n",
        "X_train[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Boqr6ROYf9z6"
      },
      "source": [
        "# create model\n",
        "model = text.text_classifier(name='bert',\n",
        "                             train_data=(X_train, y_train),\n",
        "                             preproc=preprocess)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfAl2iMogqeB"
      },
      "source": [
        "# compile model\n",
        "learner = ktrain.get_learner(model=model,\n",
        "                             train_data=(X_train, y_train),\n",
        "                             val_data=(X_val, y_val),\n",
        "                             batch_size=6)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0u_eD-Zhtf1"
      },
      "source": [
        "# train model - depending on the task this cell often takes a while to run\n",
        "learner.fit_onecycle(lr=2e-5, epochs=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89zxxcIti2ry"
      },
      "source": [
        "# get predictions for test set\n",
        "predictor = ktrain.get_predictor(learner.model, preprocess)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKV3CbhLjYIp"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# produce predictions\n",
        "predicted = predictor.predict(test_tweets)\n",
        "print(predicted)\n",
        "\n",
        "# use for emotion\n",
        "predictions = []\n",
        "for i in predicted:\n",
        "  if i == 'Target_0':\n",
        "    predictions.append(0)\n",
        "  elif i == 'Target_1':\n",
        "    predictions.append(1)\n",
        "  elif i == 'Target_2':\n",
        "    predictions.append(2)\n",
        "  elif i == 'Target_3':\n",
        "    predictions.append(3)\n",
        "\n",
        "# use for offensive\n",
        "# predictions = []\n",
        "# for i in predicted:\n",
        "#   if i == 'not_Target':\n",
        "#     predictions.append(0)\n",
        "#   elif i == 'Target':\n",
        "#     predictions.append(1)\n",
        "\n",
        "# use for sentiment\n",
        "# predictions = []\n",
        "# for i in predicted:\n",
        "#   if i == 'Target_0':\n",
        "#     predictions.append(0)\n",
        "#   elif i == 'Target_1':\n",
        "#     predictions.append(1)\n",
        "#   elif i == 'Target_2':\n",
        "#     predictions.append(2)\n",
        "\n",
        "# check results\n",
        "# print f1 score\n",
        "from sklearn.metrics import f1_score, recall_score\n",
        "f1 = f1_score(test_labels, predictions, average='macro')\n",
        "mar = f1_score(test_labels, predictions, average='macro')\n",
        "conf_matrix = confusion_matrix(test_labels, predictions)\n",
        "print(\"Macro F1 score: \", f1)\n",
        "print(\"Macro average recall score: \", mar)\n",
        "\n",
        "# display confusion matrix\n",
        "sns.heatmap(conf_matrix, annot=True, fmt = \".0f\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1q3vKfAhkefU"
      },
      "source": [
        "# save model\n",
        "predictor.save('/content/bert')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuH5-TTSoCiZ"
      },
      "source": [
        "# functionality to reload model\n",
        "predictor_loaded = ktrain.load_predictor('/content/bert')\n",
        "predicted = predictor_loaded.predict(test_tweets)\n",
        "print(predicted)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}